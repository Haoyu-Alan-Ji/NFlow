{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae960986",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def set_seed(seed: int = 0):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Target distribution: 2D mixture of Gaussians (4 modes)\n",
    "# ----------------------------\n",
    "def sample_target(n: int, device):\n",
    "    \"\"\"\n",
    "    生成 2D 四峰高斯混合数据，方便肉眼看多峰结构。\n",
    "    \"\"\"\n",
    "    means = torch.tensor(\n",
    "        [\n",
    "            [2.0, 2.0],\n",
    "            [2.0, -2.0],\n",
    "            [-2.0, 2.0],\n",
    "            [-2.0, -2.0],\n",
    "        ],\n",
    "        device=device,\n",
    "    )\n",
    "    # 每个分量方差相同\n",
    "    std = 0.35\n",
    "\n",
    "    # 随机选分量\n",
    "    k = torch.randint(0, 4, (n,), device=device)\n",
    "    eps = torch.randn(n, 2, device=device) * std\n",
    "    x = means[k] + eps\n",
    "    return x\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Small MLP to produce s(.) or t(.)\n",
    "# Input: scalar (conditioned dim), Output: scalar (for transformed dim)\n",
    "# ----------------------------\n",
    "class ScalarMLP(nn.Module):\n",
    "    def __init__(self, hidden=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (N, 1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2D RealNVP-style coupling layer:\n",
    "# x1 = z1\n",
    "# x2 = z2 * exp(s(z1)) + t(z1)\n",
    "# Invertible because exp(s)>0\n",
    "# ----------------------------\n",
    "class CouplingLayer2D(nn.Module):\n",
    "    def __init__(self, hidden=64, clamp_s=5.0, swap=False):\n",
    "        \"\"\"\n",
    "        swap=False: condition on dim0, transform dim1\n",
    "        swap=True : condition on dim1, transform dim0 (通过交换维度实现)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.s_net = ScalarMLP(hidden)\n",
    "        self.t_net = ScalarMLP(hidden)\n",
    "        self.clamp_s = clamp_s\n",
    "        self.swap = swap\n",
    "\n",
    "    def _st(self, cond):  # cond: (N,) -> (N,)\n",
    "        cond = cond.unsqueeze(1)  # (N,1)\n",
    "        s = self.s_net(cond).squeeze(1)\n",
    "        t = self.t_net(cond).squeeze(1)\n",
    "        # 防止 exp(s) 爆炸，训练更稳定\n",
    "        s = torch.clamp(s, -self.clamp_s, self.clamp_s)\n",
    "        return s, t\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        z -> x, return (x, logdet)\n",
    "        logdet = sum log|det dx/dz| per sample\n",
    "        \"\"\"\n",
    "        if self.swap:\n",
    "            z = z[:, [1, 0]]  # swap dims\n",
    "\n",
    "        z1, z2 = z[:, 0], z[:, 1]\n",
    "        s, t = self._st(z1)\n",
    "\n",
    "        x1 = z1\n",
    "        x2 = z2 * torch.exp(s) + t\n",
    "        x = torch.stack([x1, x2], dim=1)\n",
    "\n",
    "        if self.swap:\n",
    "            x = x[:, [1, 0]]  # swap back\n",
    "\n",
    "        logdet = s  # (N,) because Jacobian triangular with diag = [1, exp(s)]\n",
    "        return x, logdet\n",
    "\n",
    "    def inverse(self, x):\n",
    "        \"\"\"\n",
    "        x -> z, return (z, logdet_inv)\n",
    "        logdet_inv = sum log|det dz/dx| per sample\n",
    "        \"\"\"\n",
    "        if self.swap:\n",
    "            x = x[:, [1, 0]]\n",
    "\n",
    "        x1, x2 = x[:, 0], x[:, 1]\n",
    "        s, t = self._st(x1)\n",
    "\n",
    "        z1 = x1\n",
    "        z2 = (x2 - t) * torch.exp(-s)\n",
    "        z = torch.stack([z1, z2], dim=1)\n",
    "\n",
    "        if self.swap:\n",
    "            z = z[:, [1, 0]]\n",
    "\n",
    "        logdet_inv = -s\n",
    "        return z, logdet_inv\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Flow model: stack coupling layers\n",
    "# ----------------------------\n",
    "class RealNVP2D(nn.Module):\n",
    "    def __init__(self, num_layers=6, hidden=64):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for k in range(num_layers):\n",
    "            layers.append(CouplingLayer2D(hidden=hidden, swap=(k % 2 == 1)))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        # base distribution: standard normal in R^2\n",
    "        self.base = torch.distributions.Normal(0.0, 1.0)\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        \"\"\"\n",
    "        log p(x) = log p(z) + log|det dz/dx|\n",
    "        where z = f^{-1}(x)\n",
    "        \"\"\"\n",
    "        z = x\n",
    "        logdet_sum = torch.zeros(x.shape[0], device=x.device)\n",
    "        for layer in reversed(self.layers):\n",
    "            z, logdet_inv = layer.inverse(z)\n",
    "            logdet_sum += logdet_inv\n",
    "\n",
    "        # base log prob: sum over dims\n",
    "        logp_z = self.base.log_prob(z).sum(dim=1)\n",
    "        return logp_z + logdet_sum\n",
    "\n",
    "    def sample(self, n, device):\n",
    "        z = self.base.sample((n, 2)).to(device)\n",
    "        x = z\n",
    "        # forward through layers\n",
    "        for layer in self.layers:\n",
    "            x, _ = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def check_invertibility(self, device):\n",
    "        with torch.no_grad():\n",
    "            z0 = torch.randn(256, 2, device=device)\n",
    "            x, _ = self.layers[0].forward(z0)  # check first layer quickly\n",
    "            z1, _ = self.layers[0].inverse(x)\n",
    "            err = (z1 - z0).abs().max().item()\n",
    "        return err\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Training + visualization\n",
    "# ----------------------------\n",
    "def main():\n",
    "    set_seed(0)\n",
    "    device = get_device()\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    # Model\n",
    "    flow = RealNVP2D(num_layers=6, hidden=64).to(device)\n",
    "\n",
    "    # Quick invertibility check (single layer)\n",
    "    err = flow.check_invertibility(device)\n",
    "    print(\"invertibility check (layer 0) max |z_rec - z| =\", err)\n",
    "\n",
    "    # Data\n",
    "    n_data = 20000\n",
    "    x_data = sample_target(n_data, device=device)\n",
    "\n",
    "    # Optimizer\n",
    "    opt = torch.optim.Adam(flow.parameters(), lr=1e-3)\n",
    "\n",
    "    # Training\n",
    "    steps = 2000\n",
    "    batch_size = 512\n",
    "\n",
    "    for step in range(1, steps + 1):\n",
    "        idx = torch.randint(0, n_data, (batch_size,), device=device)\n",
    "        xb = x_data[idx]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        nll = -flow.log_prob(xb).mean()\n",
    "        nll.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if step % 200 == 0:\n",
    "            print(f\"step {step:4d} | NLL {nll.item():.4f}\")\n",
    "\n",
    "    # Sample from trained flow\n",
    "    with torch.no_grad():\n",
    "        x_model = flow.sample(5000, device=device).cpu()\n",
    "        x_true = sample_target(5000, device=device).cpu()\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axes[0].scatter(x_true[:, 0], x_true[:, 1], s=5)\n",
    "    axes[0].set_title(\"Target samples\")\n",
    "    axes[0].set_aspect(\"equal\", \"box\")\n",
    "\n",
    "    axes[1].scatter(x_model[:, 0], x_model[:, 1], s=5)\n",
    "    axes[1].set_title(\"Flow samples\")\n",
    "    axes[1].set_aspect(\"equal\", \"box\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"DONE\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
